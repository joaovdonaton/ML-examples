{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159345af-4f30-405f-9500-d153e8f9925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/joao/.cache/kagglehub/datasets/hassan06/nslkdd/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# get dataset\n",
    "path = kagglehub.dataset_download(\"hassan06/nslkdd\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "train_name, test_name = 'KDDTrain+.arff', 'KDDTest+.arff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644607da-30c7-4bb7-bd6a-98181e629890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# couldn't get arff loading libaries to work, so I'll do it manually\n",
    "def parse_arff(p):\n",
    "    with open(p, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        attribute_strings = [l.replace('\\n', '').replace('@attribute ', '') for l in lines if l.startswith('@attribute')]\n",
    "\n",
    "        attributes = {}\n",
    "        for s in attribute_strings:\n",
    "            # we only have attribute type real or categorical in this dataset\n",
    "            att_name = s[0:s.find(' ')].replace('\\'', '')\n",
    "            if s.endswith('real'):\n",
    "                attributes[att_name] = 'real'\n",
    "            else:\n",
    "                attributes[att_name] = eval(s[s.find(' ')+1:])\n",
    "\n",
    "        data_ind = -1 # data starts at this index\n",
    "        for i in range(len(lines)):\n",
    "            if lines[i].find('@data') != -1:\n",
    "                data_ind = i+1\n",
    "        \n",
    "        data = [] \n",
    "        positional_attribs = list(attributes.items()) # python 3.7+ guarantees dict order of insertion\n",
    "        for d in lines[data_ind:]:\n",
    "            attribs = d.replace('\\n', '').split(',')\n",
    "            row = []\n",
    "            for i in range(len(attribs)):\n",
    "                if positional_attribs[i][1] == 'real' or str(positional_attribs[i][1]) == '{\\'0\\', \\'1\\'}':\n",
    "                    row.append(float(attribs[i]))\n",
    "                else:\n",
    "                    row.append(str(attribs[i]))\n",
    "            data.append(row)\n",
    "\n",
    "    return attributes, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40db749-9534-41cf-b860-6055e59bc4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes, train_data = parse_arff(path+'/'+train_name)\n",
    "\n",
    "train_data_df = pd.DataFrame(train_data, columns=list(attributes.keys()))\n",
    "\n",
    "# exclude anomalous entries for encoder training\n",
    "train_data_df = train_data_df[train_data_df['class'] == 'normal']\n",
    "train_data_df = train_data_df.drop(columns=['class'])\n",
    "\n",
    "# one hot encode categorical data\n",
    "train_data_df['service'] = pd.Categorical(train_data_df['service'], categories=attributes['service'])\n",
    "train_data_df['flag'] = pd.Categorical(train_data_df['flag'], categories=attributes['flag'])\n",
    "train_data_df = pd.get_dummies(train_data_df, columns=['protocol_type', 'service', 'flag'])\n",
    "\n",
    "#train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea12ae78-7fd6-4bf6-a1a4-e80abfcde8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for column 0 (duration) std is 1304.44: 545\n",
      "\t z-score of 6 corresponds to 7826.65\n",
      "for column 1 (src_bytes) std is 418110.03: 16\n",
      "\t z-score of 6 corresponds to 2508660.18\n",
      "for column 2 (dst_bytes) std is 65462.33: 71\n",
      "\t z-score of 6 corresponds to 392773.99\n",
      "for column 3 (land) std is 0.01: 7\n",
      "\t z-score of 6 corresponds to 0.06\n",
      "for column 5 (urgent) std is 0.02: 6\n",
      "\t z-score of 6 corresponds to 0.10\n",
      "for column 6 (hot) std is 2.31: 520\n",
      "\t z-score of 6 corresponds to 13.85\n",
      "for column 7 (num_failed_logins) std is 0.05: 68\n",
      "\t z-score of 6 corresponds to 0.30\n",
      "for column 8 (logged_in) std is 0.45: 0\n",
      "\t z-score of 6 corresponds to 2.72\n",
      "for column 9 (num_compromised) std is 32.74: 43\n",
      "\t z-score of 6 corresponds to 196.46\n",
      "for column 10 (root_shell) std is 0.05: 137\n",
      "\t z-score of 6 corresponds to 0.27\n",
      "for column 11 (su_attempted) std is 0.06: 79\n",
      "\t z-score of 6 corresponds to 0.37\n",
      "for column 12 (num_root) std is 33.37: 45\n",
      "\t z-score of 6 corresponds to 200.21\n",
      "for column 13 (num_file_creations) std is 0.65: 81\n",
      "\t z-score of 6 corresponds to 3.91\n",
      "for column 14 (num_shells) std is 0.03: 39\n",
      "\t z-score of 6 corresponds to 0.16\n",
      "for column 15 (num_access_files) std is 0.14: 361\n",
      "\t z-score of 6 corresponds to 0.81\n",
      "for column 19 (count) std is 54.03: 182\n",
      "\t z-score of 6 corresponds to 324.15\n",
      "for column 20 (srv_count) std is 60.18: 134\n",
      "\t z-score of 6 corresponds to 361.09\n",
      "for column 28 (dst_host_count) std is 101.78: 0\n",
      "\t z-score of 6 corresponds to 610.71\n",
      "for column 29 (dst_host_srv_count) std is 92.61: 0\n",
      "\t z-score of 6 corresponds to 555.65\n"
     ]
    }
   ],
   "source": [
    "# before normalizing, let's see if we don't have any huge outliers since we're doing minmax scaling\n",
    "# we can exclude our hot encoded ones, and also ignore any of the rate features or booleans\n",
    "columns = list(train_data_df.columns)\n",
    "excluded_indexes = [i for i in range(columns.index('protocol_type_icmp'), len(columns))]\n",
    "\n",
    "train_data_np = train_data_df.to_numpy()\n",
    "for i in range(len(columns)):\n",
    "    if i not in excluded_indexes:\n",
    "        col = train_data_np[:, i]\n",
    "        std = col.std()\n",
    "        if std != 0 and columns[i].find('rate') == -1 and columns[i].find('is_') == -1: \n",
    "            z_col = col/std\n",
    "            z_col = z_col[(z_col > 6) | (z_col < -6)] # count entries that are beyond 6 z-score range\n",
    "            print(f'for column {i} ({columns[i]}) std is {std:.2f}:', len(z_col))\n",
    "            print(f'\\t z-score of 6 corresponds to {std*6:.2f}')\n",
    "    \n",
    "            # automatically filter from out dataframe\n",
    "            train_data_df = train_data_df[train_data_df[columns[i]] <= std*6]\n",
    "        \n",
    "# investigate by plotting our samples\n",
    "#plt.scatter(np.linspace(0, 100000, len(train_data_df['duration'])), train_data_df['duration'], s=1)\n",
    "\n",
    "# maybe log transform some of the fields that have 0 or large values\n",
    "train_data_df['duration'] = np.log(train_data_df['duration']+0.001)\n",
    "train_data_df['src_bytes'] = np.log(train_data_df['src_bytes']+0.001)\n",
    "train_data_df['dst_bytes'] = np.log(train_data_df['dst_bytes']+0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef652808-3d58-4b05-ac00-519272cd7bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65519\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_OTH</th>\n",
       "      <th>flag_SH</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_S2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.907755</td>\n",
       "      <td>6.196446</td>\n",
       "      <td>-6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6.907755</td>\n",
       "      <td>4.983613</td>\n",
       "      <td>-6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.907755</td>\n",
       "      <td>5.446742</td>\n",
       "      <td>9.006141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.907755</td>\n",
       "      <td>5.293310</td>\n",
       "      <td>6.040257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-6.907755</td>\n",
       "      <td>5.659486</td>\n",
       "      <td>7.719130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125965</th>\n",
       "      <td>-6.907755</td>\n",
       "      <td>7.711102</td>\n",
       "      <td>5.899900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125967</th>\n",
       "      <td>-6.907755</td>\n",
       "      <td>5.883325</td>\n",
       "      <td>5.926929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125969</th>\n",
       "      <td>2.079567</td>\n",
       "      <td>4.653970</td>\n",
       "      <td>4.976741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125970</th>\n",
       "      <td>-6.907755</td>\n",
       "      <td>7.710206</td>\n",
       "      <td>5.950645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125972</th>\n",
       "      <td>-6.907755</td>\n",
       "      <td>5.017286</td>\n",
       "      <td>-6.907755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65519 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0      -6.907755   6.196446  -6.907755   0.0             0.0     0.0  0.0   \n",
       "1      -6.907755   4.983613  -6.907755   0.0             0.0     0.0  0.0   \n",
       "3      -6.907755   5.446742   9.006141   0.0             0.0     0.0  0.0   \n",
       "4      -6.907755   5.293310   6.040257   0.0             0.0     0.0  0.0   \n",
       "12     -6.907755   5.659486   7.719130   0.0             0.0     0.0  0.0   \n",
       "...          ...        ...        ...   ...             ...     ...  ...   \n",
       "125965 -6.907755   7.711102   5.899900   0.0             0.0     0.0  0.0   \n",
       "125967 -6.907755   5.883325   5.926929   0.0             0.0     0.0  0.0   \n",
       "125969  2.079567   4.653970   4.976741   0.0             0.0     0.0  0.0   \n",
       "125970 -6.907755   7.710206   5.950645   0.0             0.0     0.0  0.0   \n",
       "125972 -6.907755   5.017286  -6.907755   0.0             0.0     0.0  0.0   \n",
       "\n",
       "        num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_S0  \\\n",
       "0                     0.0        0.0              0.0  ...     False    False   \n",
       "1                     0.0        0.0              0.0  ...     False    False   \n",
       "3                     0.0        1.0              0.0  ...     False    False   \n",
       "4                     0.0        1.0              0.0  ...     False    False   \n",
       "12                    0.0        1.0              0.0  ...     False    False   \n",
       "...                   ...        ...              ...  ...       ...      ...   \n",
       "125965                0.0        1.0              0.0  ...     False    False   \n",
       "125967                0.0        1.0              0.0  ...     False    False   \n",
       "125969                0.0        0.0              0.0  ...     False    False   \n",
       "125970                0.0        1.0              0.0  ...     False    False   \n",
       "125972                0.0        1.0              0.0  ...     False    False   \n",
       "\n",
       "        flag_S1  flag_RSTOS0  flag_OTH  flag_SH  flag_RSTO  flag_RSTR  \\\n",
       "0         False        False     False    False      False      False   \n",
       "1         False        False     False    False      False      False   \n",
       "3         False        False     False    False      False      False   \n",
       "4         False        False     False    False      False      False   \n",
       "12        False        False     False    False      False      False   \n",
       "...         ...          ...       ...      ...        ...        ...   \n",
       "125965    False        False     False    False      False      False   \n",
       "125967    False        False     False    False      False      False   \n",
       "125969    False        False     False    False      False      False   \n",
       "125970    False        False     False    False      False      False   \n",
       "125972    False        False     False    False      False      False   \n",
       "\n",
       "        flag_SF  flag_S2  \n",
       "0          True    False  \n",
       "1          True    False  \n",
       "3          True    False  \n",
       "4          True    False  \n",
       "12         True    False  \n",
       "...         ...      ...  \n",
       "125965     True    False  \n",
       "125967     True    False  \n",
       "125969     True    False  \n",
       "125970     True    False  \n",
       "125972     True    False  \n",
       "\n",
       "[65519 rows x 122 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_data_df))\n",
    "train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c46afc5-b23f-476d-95f4-e702d5ca571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "data = scaler.fit_transform(train_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "641b598d-772a-459a-82f6-418476542228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use pytorch to implement our model\n",
    "# source for architecture: https://pmc.ncbi.nlm.nih.gov/articles/PMC8272075/pdf/sensors-21-04294.pdf\n",
    "# Apparently, it looks like different depth and hidden layer neuron numbers achieve very similar results on this dataset\n",
    "# We'll go for a symmetric autoencoder with depth of 5 with 64 neurons on the first hidden layer (subsequent layers divide number of neurons by 2)\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, latent_dim),\n",
    "            # torch.nn.ReLU() MAYBE?\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, input_dim),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "\n",
    "class SampleDataset(Dataset): # want this so I can use dataloader\n",
    "    def __init__(self, data_matrix):\n",
    "        self.data = torch.from_numpy(data_matrix).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        return self.data[ind]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db2ad599-73aa-4bc0-afb4-a6898efec57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(data.shape[1], 3)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n",
    "\n",
    "#model.forward(torch.from_numpy(data[0]).float())\n",
    "\n",
    "loss_fun = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "dataset = SampleDataset(data)\n",
    "loader = DataLoader(dataset, shuffle=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8b30fc6-4a8d-407a-8b11-bbe4de6484ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.6082, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0062, 0.0062, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "        0.0000, 0.5882, 0.0980, 0.1700, 0.0300, 0.1700, 0.0000, 0.0000, 0.0000,\n",
      "        0.0500, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 1.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82535d41-0d19-4a09-a94e-2723b230475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT EPOCH 0\n",
      "0.24031653448939325\n",
      "0.22776384241878986\n",
      "0.1874408857151866\n",
      "0.1469528790935874\n",
      "0.12148848837800325\n",
      "0.10430685265300174\n",
      "0.09195783603138158\n",
      "0.08272845630766824\n",
      "0.07552256415701575\n",
      "0.06974134288355709\n",
      "AT EPOCH 1\n",
      "0.017258514072746037\n",
      "0.01734172018710524\n",
      "0.017247166621188324\n",
      "0.017123852344229817\n",
      "0.01708869778364897\n",
      "0.017047648926575978\n",
      "0.016930792961003523\n",
      "0.016829136110609398\n",
      "0.016748805321339103\n",
      "0.01668443994410336\n",
      "AT EPOCH 2\n",
      "0.01614089298993349\n",
      "0.015887559014372526\n",
      "0.015622351358955105\n",
      "0.015484385802410542\n",
      "0.015322304330766201\n",
      "0.01523466595603774\n",
      "0.015111623040533491\n",
      "0.015008240297902375\n",
      "0.014857920128852129\n",
      "0.014697314908728004\n",
      "AT EPOCH 3\n",
      "0.012787501877173781\n",
      "0.012629493023268878\n",
      "0.012452258526658018\n",
      "0.012233073894167319\n",
      "0.012011222933419049\n",
      "0.011819901808630675\n",
      "0.011610535587450224\n",
      "0.011415485759498552\n",
      "0.011219586383344398\n",
      "0.011045305291190743\n",
      "AT EPOCH 4\n",
      "0.00884223723784089\n",
      "0.008741689568851144\n",
      "0.008679682317500314\n",
      "0.00852140483330004\n",
      "0.008363124991767109\n",
      "0.008177728407705824\n",
      "0.007990608295824911\n",
      "0.00781278966460377\n",
      "0.007618875195168786\n",
      "0.007441393338376656\n",
      "AT EPOCH 5\n",
      "0.005770309220533818\n",
      "0.005783494848292321\n",
      "0.005727703411442538\n",
      "0.005699360161670484\n",
      "0.00569275732152164\n",
      "0.0056664902231811235\n",
      "0.005631228460198534\n",
      "0.005599358889448922\n",
      "0.005562219856720832\n",
      "0.005531281489646062\n",
      "AT EPOCH 6\n",
      "0.00506857440341264\n",
      "0.005159146476071328\n",
      "0.005098792544255654\n",
      "0.0050891640211921186\n",
      "0.005062371426727622\n",
      "0.005044608787866309\n",
      "0.0050214071026338\n",
      "0.004964010429102927\n",
      "0.004921409786782331\n",
      "0.004883458394557238\n",
      "AT EPOCH 7\n",
      "0.00469273513648659\n",
      "0.00461074587656185\n",
      "0.004526203677523881\n",
      "0.004482981011387892\n",
      "0.0044921304429881275\n",
      "0.004449265917452673\n",
      "0.00443451664443793\n",
      "0.004404849110578653\n",
      "0.004386561465863552\n",
      "0.004355617522960529\n",
      "AT EPOCH 8\n",
      "0.0041488354397006336\n",
      "0.004166222620988265\n",
      "0.004130715574913969\n",
      "0.00413558651052881\n",
      "0.004094573313836008\n",
      "0.004072003187999751\n",
      "0.004051070305618591\n",
      "0.004014699305553222\n",
      "0.004005698936008331\n",
      "0.00399820715887472\n",
      "AT EPOCH 9\n",
      "0.0037837031041271984\n",
      "0.00384276220924221\n",
      "0.0038170317839831113\n",
      "0.003767484739946667\n",
      "0.0037589594640303403\n",
      "0.00378050854022149\n",
      "0.00375550330184134\n",
      "0.003736356779554626\n",
      "0.0037224345991853625\n",
      "0.0037144868924515323\n",
      "AT EPOCH 10\n",
      "0.0036700796731747687\n",
      "0.003699903324013576\n",
      "0.0036344314948655665\n",
      "0.0035409935720963404\n",
      "0.0035347026013769207\n",
      "0.0034958112915046513\n",
      "0.0034762429352849723\n",
      "0.003469070047722198\n",
      "0.0034622711295055016\n",
      "0.0034437033490976317\n",
      "AT EPOCH 11\n",
      "0.00326024328591302\n",
      "0.0032441859133541585\n",
      "0.003255415417176361\n",
      "0.00323278714902699\n",
      "0.0032121450931299478\n",
      "0.003206836911267601\n",
      "0.003195216933631205\n",
      "0.003185156131221447\n",
      "0.0031736043619457633\n",
      "0.003163497755303979\n",
      "AT EPOCH 12\n",
      "0.0030452208302449435\n",
      "0.0029906435374869034\n",
      "0.002944526852030928\n",
      "0.002934305575618055\n",
      "0.0029223151567857714\n",
      "0.0029205701333315424\n",
      "0.002919306102308578\n",
      "0.0029166895731759725\n",
      "0.002907429364794451\n",
      "0.0029071428931783886\n",
      "AT EPOCH 13\n",
      "0.002815973149845377\n",
      "0.0027888108295155687\n",
      "0.0028321796519837033\n",
      "0.00281063689122675\n",
      "0.0027934828652068974\n",
      "0.002798161168660348\n",
      "0.0027904510356685413\n",
      "0.002782676954957424\n",
      "0.0027679212643609693\n",
      "0.0027598679616348816\n",
      "AT EPOCH 14\n",
      "0.0026829634251771496\n",
      "0.002675254484056495\n",
      "0.0026471337998130668\n",
      "0.00264707884110976\n",
      "0.0026589714714791626\n",
      "0.0026477214249704655\n",
      "0.002665617595859138\n",
      "0.002673910678058746\n",
      "0.0026711539288387736\n",
      "0.0026635769099812023\n",
      "AT EPOCH 15\n",
      "0.002474716962315142\n",
      "0.002585551438387483\n",
      "0.0026255510956980288\n",
      "0.0026211866486119105\n",
      "0.002617835796670988\n",
      "0.0026148070743268665\n",
      "0.002608388177135826\n",
      "0.002594465677902917\n",
      "0.002595596723452521\n",
      "0.00260045043687569\n",
      "AT EPOCH 16\n",
      "0.002492215539095923\n",
      "0.002532548900344409\n",
      "0.0025619049418795234\n",
      "0.0025401086204510648\n",
      "0.002541909617721103\n",
      "0.0025437823856676307\n",
      "0.0025336094702028537\n",
      "0.0025249263791920383\n",
      "0.0025348943939510113\n",
      "0.002533857459144201\n",
      "AT EPOCH 17\n",
      "0.0025951600208645688\n",
      "0.002550807959923986\n",
      "0.0025836408446775747\n",
      "0.0025471676398592536\n",
      "0.002535814061644487\n",
      "0.002526645134300149\n",
      "0.0025054127420298753\n",
      "0.0025037445846828633\n",
      "0.0024934217603489136\n",
      "0.00248663545754971\n",
      "AT EPOCH 18\n",
      "0.002407928268657997\n",
      "0.002436058969469741\n",
      "0.002457778600122159\n",
      "0.002452786286594346\n",
      "0.002433625708101317\n",
      "0.0024364408066806695\n",
      "0.002435181255319289\n",
      "0.002433595736583811\n",
      "0.0024420050881518466\n",
      "0.0024397774135577494\n",
      "AT EPOCH 19\n",
      "0.002408809812623076\n",
      "0.0024005849621607923\n",
      "0.0024105294646384816\n",
      "0.0024177306139608846\n",
      "0.002397297831601463\n",
      "0.0024234877164902476\n",
      "0.002432177635325518\n",
      "0.002414268350985367\n",
      "0.002413486050338381\n",
      "0.002413562171161175\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCH = 20\n",
    "\n",
    "loss_log = []\n",
    "for e in range(MAX_EPOCH):\n",
    "    print('AT EPOCH ' + str(e))\n",
    "    loss_sum = 0\n",
    "    count = 0\n",
    "    for s in loader:\n",
    "        count += 1\n",
    "        if torch.cuda.is_available():\n",
    "            s = s.to('cuda')\n",
    "        \n",
    "        output = model.forward(s)\n",
    "        loss = loss_fun(output, s)\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            loss_log.append(loss_sum/count)\n",
    "            print(loss_sum/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c1dd98e-e663-4b43-9e27-e7fbed023134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd9ec318ef0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0, len(loss_log), len(loss_log)), loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e672260-54ca-477b-b9b3-2d4d0d3df566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
