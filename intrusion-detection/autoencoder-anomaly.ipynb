{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "159345af-4f30-405f-9500-d153e8f9925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/joao/.cache/kagglehub/datasets/hassan06/nslkdd/versions/1\n",
      "{'aol', 'hostnames', 'finger', 'efs', 'gopher', 'http', 'remote_job', 'csnet_ns', 'urh_i', 'auth', 'http_443', 'http_2784', 'tim_i', 'vmnet', 'echo', 'imap4', 'ctf', 'ssh', 'netstat', 'sunrpc', 'ftp_data', 'login', 'private', 'http_8001', 'telnet', 'pop_3', 'red_i', 'exec', 'nnsp', 'ldap', 'printer', 'Z39_50', 'IRC', 'time', 'netbios_dgm', 'rje', 'urp_i', 'eco_i', 'discard', 'courier', 'daytime', 'sql_net', 'link', 'smtp', 'ftp', 'pm_dump', 'uucp', 'X11', 'supdup', 'netbios_ns', 'ntp_u', 'kshell', 'netbios_ssn', 'shell', 'name', 'tftp_u', 'ecr_i', 'bgp', 'nntp', 'uucp_path', 'iso_tsap', 'domain_u', 'mtp', 'systat', 'whois', 'other', 'domain', 'pop_2', 'harvest', 'klogin'}\n"
     ]
    }
   ],
   "source": [
    "# get NSL-KDD dataset\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "path = kagglehub.dataset_download(\"hassan06/nslkdd\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "train_name, test_name = 'KDDTrain+.arff', 'KDDTest+.arff'\n",
    "\n",
    "# couldn't get arff loading libaries to work, so I'll do it manually\n",
    "def parse_arff(p):\n",
    "    with open(p, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        attribute_strings = [l.replace('\\n', '').replace('@attribute ', '') for l in lines if l.startswith('@attribute')]\n",
    "\n",
    "        attributes = {}\n",
    "        for s in attribute_strings:\n",
    "            # we only have attribute type real or categorical in this dataset\n",
    "            att_name = s[0:s.find(' ')].replace('\\'', '')\n",
    "            if s.endswith('real'):\n",
    "                attributes[att_name] = 'real'\n",
    "            else:\n",
    "                attributes[att_name] = eval(s[s.find(' ')+1:])\n",
    "\n",
    "        data_ind = -1 # data starts at this index\n",
    "        for i in range(len(lines)):\n",
    "            if lines[i].find('@data') != -1:\n",
    "                data_ind = i+1\n",
    "        \n",
    "        data = [] \n",
    "        positional_attribs = list(attributes.items()) # python 3.7+ guarantees dict order of insertion\n",
    "        for d in lines[data_ind:]:\n",
    "            attribs = d.replace('\\n', '').split(',')\n",
    "            row = []\n",
    "            for i in range(len(attribs)):\n",
    "                row.append(float(attribs[i]) if positional_attribs[i][1] == 'real' else str(attribs[i]))\n",
    "            data.append(row)\n",
    "\n",
    "    return attributes, data\n",
    "\n",
    "attributes, data = parse_arff(path+'/'+train_name)\n",
    "\n",
    "print(attributes['service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644607da-30c7-4bb7-bd6a-98181e629890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
