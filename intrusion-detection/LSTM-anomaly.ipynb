{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec2e6fd0-f3c2-4db8-abbc-a5d99dce6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# TODO: figure out where I want to do data normalization, decide what features to keep or not\n",
    "\n",
    "RAW_DATA_PATH = \"./data/UNSW-NB15_?.csv\" # replace ? with 1,2,3,4\n",
    "FEATURE_PATH = \"./data/NUSW-NB15_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b5680-8020-4ba3-b26d-e6f82a59e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets (see README.md for source)\n",
    "\n",
    "features = pd.read_csv(FEATURE_PATH, encoding='cp1252').drop(columns=['No.'])\n",
    "column_names = list(features['Name'])\n",
    "column_types = {}\n",
    "\n",
    "# for some reason there is some weirdness columns like ports being in hexadecimal sometimes?\n",
    "for ind, row in features.iterrows():\n",
    "    typ = row['Type '].lower()\n",
    "    if typ == 'nominal':\n",
    "        column_types[row['Name']] = str\n",
    "    elif typ == 'integer' or typ == 'timestamp' or typ == 'binary':\n",
    "        column_types[row['Name']] = np.int64\n",
    "    elif typ == 'float':\n",
    "        column_types[row['Name']] = np.float64\n",
    "\n",
    "dfs = []\n",
    "for i in range(1,5):\n",
    "    temp = pd.read_csv(RAW_DATA_PATH.replace('?', str(i)), names=column_names)\n",
    "\n",
    "    dfs.append(temp)\n",
    "\n",
    "raw_data = pd.concat(dfs)\n",
    "\n",
    "# sport and dport are string instead of int because there are some weird entries \n",
    "# exclude rows with '-' ports and convert hex ports to int \n",
    "exclude_ind = []\n",
    "\n",
    "for ind, d in raw_data.iterrows():\n",
    "    if d['sport'] == '-' or d['dsport'] == '-':\n",
    "        exclude_ind.append(ind)\n",
    "\n",
    "raw_data = raw_data.drop(exclude_ind)\n",
    "\n",
    "# convert the hex values to ints\n",
    "def convert_to_int(v): \n",
    "    if type(v) == str:\n",
    "        return int(v, 16)\n",
    "    return v\n",
    "\n",
    "raw_data['sport'] = raw_data['sport'].apply(convert_to_int)\n",
    "raw_data['dsport'] = raw_data['dsport'].apply(convert_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3aa08b-b778-408f-8a66-3aa5f56ef039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to break out data into sequences\n",
    "TIME_WINDOW = 60 * 2 \n",
    "\n",
    "raw_data = raw_data.sort_values(by=['Stime'])\n",
    "\n",
    "groups = raw_data.groupby(by=['srcip', 'dstip']) # should be same order as in original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc95ddc-720e-4427-bca4-a09bfc5ab134",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seq = {}\n",
    "for name, g in groups:\n",
    "    sequences = []\n",
    "    window_start_time = 0\n",
    "    current_seq = []\n",
    "    for ind, data in g.iterrows():\n",
    "        if window_start_time == 0:\n",
    "            window_start_time = data['Stime']\n",
    "        \n",
    "        current_seq.append(data)\n",
    "    \n",
    "        if (data['Stime']-window_start_time) >= TIME_WINDOW:\n",
    "            window_start_time = 0\n",
    "            sequences.append(current_seq)\n",
    "            current_seq = []\n",
    "\n",
    "    all_seq[name] = sequences\n",
    "    #print(f'{name} has {len(sequences)} sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9956949-d651-4786-955e-cc7a39822f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 79616 sequences in our dataset\n",
      "Out of these, 9859 contain attacks\n"
     ]
    }
   ],
   "source": [
    "# Analysis and filtering of sequence data\n",
    "MIN_SEQ_COUNT = 30 # want to exclude IP pairs that have less than 30 sequences, since these may not provide enough information to be relevant for training\n",
    "\n",
    "raw_sequences = []\n",
    "attack_indices = []\n",
    "for k, v in all_seq.items():\n",
    "    seq_count = len(v)\n",
    "    \n",
    "    lengths = [len(d) for d in v]\n",
    "    if len(lengths) > MIN_SEQ_COUNT:\n",
    "        #print(f'{k}: {len(v)} total sequences, {min(lengths)} min length, {max(lengths)} max length, {statistics.mean(lengths):.2f} average length')\n",
    "\n",
    "        for s in v:\n",
    "            raw_sequences.append(s)\n",
    "            \n",
    "            for con in s:\n",
    "                if con['Label'] == 1:\n",
    "                    attack_indices.append(len(raw_sequences)-1)\n",
    "                    break\n",
    "\n",
    "print(f'We have {len(raw_sequences)} sequences in our dataset')\n",
    "print(f'Out of these, {len(attack_indices)} contain attacks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4852707c-c09a-450d-881b-9dd403a290e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "def raw_sequence_2_tensor(seq):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "86177779-df5b-4494-90c9-f4780f1664a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_seq_2_tesnor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_sequences[index], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_labels[index]\n\u001b[1;32m     17\u001b[0m ds \u001b[38;5;241m=\u001b[39m SequenceDataset(raw_sequences, attack_indices)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mraw_seq_2_tesnor\u001b[49m(ds[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw_seq_2_tesnor' is not defined"
     ]
    }
   ],
   "source": [
    "# Dataset class\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, sequences, attack_inds):\n",
    "        self.raw_sequences = sequences\n",
    "        self.raw_labels = []\n",
    "\n",
    "        for index, s in enumerate(self.raw_sequences):\n",
    "            self.raw_labels.append(1 if index in attack_inds else 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.raw_sequences[index], self.raw_labels[index]\n",
    "\n",
    "\n",
    "ds = SequenceDataset(raw_sequences, attack_indices)\n",
    "raw_seq_2_tensor(ds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7378e7f1-c0a1-4d1b-92e2-b210ed79607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG CODE\n",
    "\n",
    "for j in dfs:\n",
    "    zero_cnt = 0\n",
    "    for i in j['Stime'].to_numpy():\n",
    "        if i == 0: zero_cnt += 1\n",
    "\n",
    "zero_cnt\n",
    "\n",
    "###\n",
    "for i in range(len(column_names)):\n",
    "    print(f'{column_names[i]} - {dfs[0][column_names[i]].dtype} {dfs[1][column_names[i]].dtype} {dfs[2][column_names[i]].dtype} {dfs[3][column_names[i]].dtype}')\n",
    "\n",
    "\n",
    "###\n",
    "for c in column_names:\n",
    "    print(f'Column {c} has type {raw_data[c].dtype}')\n",
    "\n",
    "### sequence generation\n",
    "g = groups.get_group(('59.166.0.0', '149.171.126.6'))\n",
    "start_times = g['Stime']\n",
    "\n",
    "sequences = []\n",
    "window_start_time = 0\n",
    "current_seq = []\n",
    "for ind, data in g.iterrows():\n",
    "    if window_start_time == 0:\n",
    "        window_start_time = data['Stime']\n",
    "    \n",
    "    #print(f'{ind} is {data['Stime']}')\n",
    "\n",
    "    current_seq.append(data)\n",
    "\n",
    "    if (data['Stime']-window_start_time) >= TIME_WINDOW:\n",
    "        window_start_time = 0\n",
    "        sequences.append(current_seq)\n",
    "        current_seq = []\n",
    "\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaeea93-206b-4987-9b29-8311a3cedb22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
